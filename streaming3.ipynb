{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.streaming import StreamingContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf()\n",
    "conf.set(\"spark.master\",\"local[2]\")\n",
    "conf.set(\"spark.app.name\",\"sparkapp\")\n",
    "sc = SparkContext(conf = conf)\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.streaming.context.StreamingContext at 0x7f8de7adcac8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssc = StreamingContext(sparkContext=sc,batchDuration=20)\n",
    "ssc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ParallelCollectionRDD[11] at parallelize at PythonRDD.scala:195, ParallelCollectionRDD[12] at parallelize at PythonRDD.scala:195, ParallelCollectionRDD[13] at parallelize at PythonRDD.scala:195, ParallelCollectionRDD[14] at parallelize at PythonRDD.scala:195, ParallelCollectionRDD[15] at parallelize at PythonRDD.scala:195, ParallelCollectionRDD[16] at parallelize at PythonRDD.scala:195, ParallelCollectionRDD[17] at parallelize at PythonRDD.scala:195, ParallelCollectionRDD[18] at parallelize at PythonRDD.scala:195, ParallelCollectionRDD[19] at parallelize at PythonRDD.scala:195, ParallelCollectionRDD[20] at parallelize at PythonRDD.scala:195]\n"
     ]
    }
   ],
   "source": [
    "queueOfRDDs = []\n",
    "for i in range(10):\n",
    "    queueOfRDDs.append(sc.parallelize([i]))\n",
    "print(queueOfRDDs)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstream_rdd = ssc.queueStream(queueOfRDDs,storageLevel = StorageLevel.MEMORY_AND_DISK)  #creation of Dstreams from a queue of RDDs\n",
    "dstream_rdd.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstream_file = ssc.textFileStream(\"file:///home/ubuntu/Stream\") \n",
    "'''\n",
    "The path must be a directory\n",
    "The file system has to be a Hadoop Compatible strage system (LFS can be used) (HDFS, S3, Azure )\n",
    "\n",
    "Spark uses Hadoop librabry for reading and writing data from external storages\n",
    "The application reads data from the new files that enter into the dir after the application gets started\n",
    "'''\n",
    "dstream_file.pprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nOnce a streaming context is stopped, It can not be reused unless it is created again\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssc.stop(stopSparkContext=False)\n",
    "'''\n",
    "Once a streaming context is stopped, It can not be reused unless it is created again\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "replicated to 0 peers instead of 1 (DEFAULT NATIRE OF PERSISTENCE IS 2 REPLCIATIONS )\n",
    "\n",
    "persistence is not fault tolerant solution if the applciation terminates abnormally\n",
    "Checkpointing will be a solution even if the applciation termantes abnormally. (meta-data  & data )\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
